{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "JoinedDataPrepared_filename = '../../SchoolData/JoinedData_2015_Prepared_Reduced.csv'\n",
    "data = pd.read_csv(JoinedDataPrepared_filename, header= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AVERAGE_DAILY_MEMBERSHIP', 'TOTAL', 'WHITE', 'AFRICAN_AMERICAN', 'HISPANIC', 'ASIAN', 'NATIVE_AMERICAN', 'HAWAIIAN_PACISLD', 'WHITE_PCT', 'AFRICAN_AMERICAN_PCT', 'HISPANIC_PCT', 'ASIAN_PCT', 'NATIVE_AMERICAN_PCT', 'HAWAIIAN_PACISLD_PCT', 'LIMITED_ENGLISH_PROFICIENT_PCT', 'LIMITED_ENGLISH_PROFICIENT', 'STUDENTS_WITH_DISABILITIES', 'STUDENTS_WITH_DISABILITIES_PCT', 'ECONOMICALLY_DISADVANTAGED', 'ECONOMICALLY_DISADVANTAGED_PCT', 'ATTENDANCE_RATE_PCT', 'EVENT_DROPOUT_PCT', 'WHITE_GRAD_RATE', 'AFRICAN_AMERICAN_GRAD_RATE', 'HISPANIC_GRAD_RATE', 'ASIAN_GRAD_RATE', 'NATIVE_AMERICAN_GRAD_RATE', 'HAWAIIAN_PACISLD_GRAD_RATE', 'ECONOMICALLY_DISADVANTAGED_GRAD_RATE', 'STUDENTS_WITH_DISABILITIES_GRAD_RATE', 'LIMITED_ENGLISH_PROFICIENT_GRAD_RATE', 'ALL_GRAD_COUNT', 'ALL_GRAD_RATE']\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "dataFields = data.columns.values.tolist()\n",
    "dataFields\n",
    "print(dataFields)\n",
    "print(len(dataFields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numerical_data = data._get_numeric_data()\n",
    "\n",
    "# put the numeric column names in a python list\n",
    "numeric_headers = list(numerical_data.columns.values)\n",
    "\n",
    "# create a numpy array with the numeric values for input into scikit-learn\n",
    "dataset = data.as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dataset_test = np.loadtxt(dataset, delimiter=\",\")\n",
    "# separate the data from the target attributes\n",
    "X = np.asarray(dataset[:,0:32])\n",
    "y = np.asarray(dataset[:,32],dtype=\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn import preprocessing\n",
    "# normalize the data attributes\n",
    "#normalized_X = preprocessing.normalize(X)\n",
    "# standardize the data attributes\n",
    "#standardized_X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False  True False  True False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False]\n",
      "[14  8 16 20  2 21 26 25  1  6  1 27 29 30 28 18 12  3 17  4  5  1 11 24 13\n",
      " 19 23 22  9 10 15  7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(X, y)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1536\n",
      "         44       1.00      1.00      1.00         1\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       1.00      1.00      1.00         2\n",
      "         51       1.00      1.00      1.00         1\n",
      "         52       1.00      1.00      1.00         1\n",
      "         55       1.00      1.00      1.00         1\n",
      "         56       1.00      1.00      1.00         1\n",
      "         61       1.00      1.00      1.00         3\n",
      "         62       1.00      1.00      1.00         1\n",
      "         63       1.00      1.00      1.00         1\n",
      "         64       1.00      1.00      1.00         2\n",
      "         65       1.00      1.00      1.00         1\n",
      "         67       1.00      1.00      1.00         1\n",
      "         68       1.00      1.00      1.00         1\n",
      "         69       0.80      1.00      0.89         4\n",
      "         73       1.00      1.00      1.00         1\n",
      "         74       1.00      0.75      0.86         4\n",
      "         75       0.67      1.00      0.80         2\n",
      "         76       1.00      1.00      1.00         2\n",
      "         77       0.80      0.80      0.80         5\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         3\n",
      "         80       0.67      0.50      0.57         4\n",
      "         81       0.25      0.25      0.25         4\n",
      "         82       0.60      1.00      0.75         3\n",
      "         83       1.00      0.50      0.67         4\n",
      "         84       0.44      0.44      0.44         9\n",
      "         85       0.50      0.45      0.48        11\n",
      "         86       0.50      0.20      0.29        10\n",
      "         87       0.36      0.33      0.35        12\n",
      "         88       0.26      0.50      0.34        14\n",
      "         89       0.57      0.33      0.42        12\n",
      "         90       0.42      0.36      0.38        14\n",
      "         91       0.38      0.47      0.42        19\n",
      "         92       0.38      0.50      0.43         6\n",
      "         93       0.33      0.22      0.27        18\n",
      "         94       0.42      0.40      0.41        25\n",
      "         95       0.53      0.50      0.51        18\n",
      "         96       0.70      0.64      0.67        22\n",
      "         97       0.82      0.82      0.82        11\n",
      "         98       0.88      0.70      0.78        10\n",
      "         99       0.56      1.00      0.71         5\n",
      "        100       0.57      1.00      0.73         4\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1811\n",
      "\n",
      "[[1536    0    0 ...,    0    0    0]\n",
      " [   0    1    0 ...,    0    0    0]\n",
      " [   0    0    1 ...,    0    0    0]\n",
      " ..., \n",
      " [   0    0    0 ...,    7    2    0]\n",
      " [   0    0    0 ...,    0    5    0]\n",
      " [   0    0    0 ...,    0    0    4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00      1536\n",
      "         44       1.00      1.00      1.00         1\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       1.00      1.00      1.00         2\n",
      "         51       1.00      1.00      1.00         1\n",
      "         52       1.00      1.00      1.00         1\n",
      "         55       1.00      1.00      1.00         1\n",
      "         56       1.00      1.00      1.00         1\n",
      "         61       1.00      1.00      1.00         3\n",
      "         62       1.00      1.00      1.00         1\n",
      "         63       1.00      1.00      1.00         1\n",
      "         64       1.00      1.00      1.00         2\n",
      "         65       1.00      1.00      1.00         1\n",
      "         67       1.00      1.00      1.00         1\n",
      "         68       1.00      1.00      1.00         1\n",
      "         69       0.80      1.00      0.89         4\n",
      "         73       1.00      1.00      1.00         1\n",
      "         74       0.75      0.75      0.75         4\n",
      "         75       1.00      1.00      1.00         2\n",
      "         76       1.00      1.00      1.00         2\n",
      "         77       0.27      0.60      0.37         5\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       0.75      1.00      0.86         3\n",
      "         80       0.40      0.50      0.44         4\n",
      "         81       0.33      0.50      0.40         4\n",
      "         82       1.00      1.00      1.00         3\n",
      "         83       0.60      0.75      0.67         4\n",
      "         84       0.50      0.11      0.18         9\n",
      "         85       0.62      0.45      0.53        11\n",
      "         86       0.75      0.30      0.43        10\n",
      "         87       0.19      0.83      0.30        12\n",
      "         88       0.38      0.21      0.27        14\n",
      "         89       0.33      0.17      0.22        12\n",
      "         90       0.47      0.57      0.52        14\n",
      "         91       0.39      0.37      0.38        19\n",
      "         92       0.50      1.00      0.67         6\n",
      "         93       0.42      0.28      0.33        18\n",
      "         94       0.75      0.12      0.21        25\n",
      "         95       0.37      0.56      0.44        18\n",
      "         96       0.41      0.32      0.36        22\n",
      "         97       0.60      0.27      0.37        11\n",
      "         98       0.69      0.90      0.78        10\n",
      "         99       1.00      1.00      1.00         5\n",
      "        100       0.80      1.00      0.89         4\n",
      "\n",
      "avg / total       0.93      0.92      0.92      1811\n",
      "\n",
      "[[1527    0    0 ...,    0    0    0]\n",
      " [   0    1    0 ...,    0    0    0]\n",
      " [   0    0    1 ...,    0    0    0]\n",
      " ..., \n",
      " [   0    0    0 ...,    9    0    0]\n",
      " [   0    0    0 ...,    0    5    0]\n",
      " [   0    0    0 ...,    0    0    4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1536\n",
      "         44       0.00      0.00      0.00         1\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       0.25      0.50      0.33         2\n",
      "         51       0.20      1.00      0.33         1\n",
      "         52       0.50      1.00      0.67         1\n",
      "         55       0.00      0.00      0.00         1\n",
      "         56       0.00      0.00      0.00         1\n",
      "         61       0.25      0.67      0.36         3\n",
      "         62       0.00      0.00      0.00         1\n",
      "         63       0.00      0.00      0.00         1\n",
      "         64       0.00      0.00      0.00         2\n",
      "         65       0.00      0.00      0.00         1\n",
      "         67       0.00      0.00      0.00         1\n",
      "         68       0.50      1.00      0.67         1\n",
      "         69       0.18      0.50      0.27         4\n",
      "         73       0.00      0.00      0.00         1\n",
      "         74       0.25      0.25      0.25         4\n",
      "         75       0.00      0.00      0.00         2\n",
      "         76       0.33      0.50      0.40         2\n",
      "         77       0.33      0.60      0.43         5\n",
      "         78       0.00      0.00      0.00         1\n",
      "         79       0.25      0.33      0.29         3\n",
      "         80       0.00      0.00      0.00         4\n",
      "         81       0.33      0.25      0.29         4\n",
      "         82       0.00      0.00      0.00         3\n",
      "         83       0.22      0.50      0.31         4\n",
      "         84       0.38      0.56      0.45         9\n",
      "         85       0.30      0.27      0.29        11\n",
      "         86       0.44      0.40      0.42        10\n",
      "         87       0.46      0.50      0.48        12\n",
      "         88       0.33      0.29      0.31        14\n",
      "         89       0.25      0.17      0.20        12\n",
      "         90       0.39      0.50      0.44        14\n",
      "         91       0.32      0.32      0.32        19\n",
      "         92       0.57      0.67      0.62         6\n",
      "         93       0.33      0.22      0.27        18\n",
      "         94       0.38      0.36      0.37        25\n",
      "         95       0.47      0.44      0.46        18\n",
      "         96       0.53      0.36      0.43        22\n",
      "         97       0.00      0.00      0.00        11\n",
      "         98       0.67      0.40      0.50        10\n",
      "         99       0.50      0.20      0.29         5\n",
      "        100       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.90      0.90      0.90      1811\n",
      "\n",
      "[[1536    0    0 ...,    0    0    0]\n",
      " [   1    0    0 ...,    0    0    0]\n",
      " [   0    0    1 ...,    0    0    0]\n",
      " ..., \n",
      " [   0    0    0 ...,    4    0    0]\n",
      " [   0    0    0 ...,    0    1    0]\n",
      " [   1    0    0 ...,    2    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/glennacree/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# fit a k-nearest neighbor model to the data\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1536\n",
      "         44       1.00      1.00      1.00         1\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       1.00      1.00      1.00         2\n",
      "         51       1.00      1.00      1.00         1\n",
      "         52       1.00      1.00      1.00         1\n",
      "         55       1.00      1.00      1.00         1\n",
      "         56       1.00      1.00      1.00         1\n",
      "         61       1.00      1.00      1.00         3\n",
      "         62       1.00      1.00      1.00         1\n",
      "         63       1.00      1.00      1.00         1\n",
      "         64       1.00      1.00      1.00         2\n",
      "         65       1.00      1.00      1.00         1\n",
      "         67       1.00      1.00      1.00         1\n",
      "         68       1.00      1.00      1.00         1\n",
      "         69       1.00      1.00      1.00         4\n",
      "         73       1.00      1.00      1.00         1\n",
      "         74       1.00      1.00      1.00         4\n",
      "         75       1.00      1.00      1.00         2\n",
      "         76       1.00      1.00      1.00         2\n",
      "         77       1.00      1.00      1.00         5\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         3\n",
      "         80       1.00      1.00      1.00         4\n",
      "         81       1.00      1.00      1.00         4\n",
      "         82       1.00      1.00      1.00         3\n",
      "         83       1.00      1.00      1.00         4\n",
      "         84       1.00      1.00      1.00         9\n",
      "         85       1.00      1.00      1.00        11\n",
      "         86       1.00      1.00      1.00        10\n",
      "         87       1.00      1.00      1.00        12\n",
      "         88       1.00      1.00      1.00        14\n",
      "         89       1.00      1.00      1.00        12\n",
      "         90       1.00      1.00      1.00        14\n",
      "         91       1.00      1.00      1.00        19\n",
      "         92       1.00      1.00      1.00         6\n",
      "         93       1.00      1.00      1.00        18\n",
      "         94       1.00      1.00      1.00        25\n",
      "         95       1.00      1.00      1.00        18\n",
      "         96       1.00      1.00      1.00        22\n",
      "         97       1.00      1.00      1.00        11\n",
      "         98       1.00      1.00      1.00        10\n",
      "         99       1.00      1.00      1.00         5\n",
      "        100       1.00      1.00      1.00         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1811\n",
      "\n",
      "[[1536    0    0 ...,    0    0    0]\n",
      " [   0    1    0 ...,    0    0    0]\n",
      " [   0    0    1 ...,    0    0    0]\n",
      " ..., \n",
      " [   0    0    0 ...,   10    0    0]\n",
      " [   0    0    0 ...,    0    5    0]\n",
      " [   0    0    0 ...,    0    0    4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1536\n",
      "         44       1.00      1.00      1.00         1\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       1.00      1.00      1.00         2\n",
      "         51       1.00      1.00      1.00         1\n",
      "         52       1.00      1.00      1.00         1\n",
      "         55       1.00      1.00      1.00         1\n",
      "         56       1.00      1.00      1.00         1\n",
      "         61       1.00      1.00      1.00         3\n",
      "         62       1.00      1.00      1.00         1\n",
      "         63       1.00      1.00      1.00         1\n",
      "         64       1.00      1.00      1.00         2\n",
      "         65       1.00      1.00      1.00         1\n",
      "         67       1.00      1.00      1.00         1\n",
      "         68       1.00      1.00      1.00         1\n",
      "         69       1.00      1.00      1.00         4\n",
      "         73       1.00      1.00      1.00         1\n",
      "         74       1.00      1.00      1.00         4\n",
      "         75       1.00      1.00      1.00         2\n",
      "         76       1.00      1.00      1.00         2\n",
      "         77       1.00      1.00      1.00         5\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         3\n",
      "         80       1.00      1.00      1.00         4\n",
      "         81       1.00      1.00      1.00         4\n",
      "         82       1.00      1.00      1.00         3\n",
      "         83       1.00      1.00      1.00         4\n",
      "         84       1.00      1.00      1.00         9\n",
      "         85       1.00      1.00      1.00        11\n",
      "         86       1.00      1.00      1.00        10\n",
      "         87       1.00      1.00      1.00        12\n",
      "         88       1.00      1.00      1.00        14\n",
      "         89       1.00      1.00      1.00        12\n",
      "         90       1.00      1.00      1.00        14\n",
      "         91       1.00      1.00      1.00        19\n",
      "         92       1.00      1.00      1.00         6\n",
      "         93       1.00      1.00      1.00        18\n",
      "         94       1.00      1.00      1.00        25\n",
      "         95       1.00      1.00      1.00        18\n",
      "         96       1.00      1.00      1.00        22\n",
      "         97       1.00      1.00      1.00        11\n",
      "         98       1.00      1.00      1.00        10\n",
      "         99       1.00      1.00      1.00         5\n",
      "        100       1.00      1.00      1.00         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1811\n",
      "\n",
      "[[1536    0    0 ...,    0    0    0]\n",
      " [   0    1    0 ...,    0    0    0]\n",
      " [   0    0    1 ...,    0    0    0]\n",
      " ..., \n",
      " [   0    0    0 ...,   10    0    0]\n",
      " [   0    0    0 ...,    0    5    0]\n",
      " [   0    0    0 ...,    0    0    4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "# fit a SVM model to the data\n",
    "model = SVC()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': array([  1.00000e+00,   1.00000e-01,   1.00000e-02,   1.00000e-03,\n",
      "         1.00000e-04,   0.00000e+00])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n",
      "-0.271907471602\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# prepare a range of alpha values to test\n",
    "alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "model = Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(X, y)\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=None, error_score='raise',\n",
      "          estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "          fit_params={}, iid=True, n_iter=100, n_jobs=1,\n",
      "          param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x11b006278>},\n",
      "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "          scoring=None, verbose=0)\n",
      "-0.271907471602\n",
      "0.6380597734899162\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "# prepare a uniform distribution to sample for the alpha parameter\n",
    "param_grid = {'alpha': sp_rand()}\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = Ridge()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100)\n",
    "rsearch.fit(X, y)\n",
    "print(rsearch)\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
